import express from "express";
import cors from "cors";
import multer from "multer";
import fs from "fs";
import fetch from "node-fetch";
import dotenv from "dotenv";

dotenv.config();

const app = express();
const PORT = 5001;
app.use(express.json());
app.use(cors());

// Multer setup for file uploads
const upload = multer({ dest: "uploads/" });

// Chatbot endpoint
app.post("/chatbot", async (req, res) => {
    const { message } = req.body;
    
    console.log("Received message:", message); // ✅ Check if the request reaches backend

    if (!message) {
        return res.status(400).json({ error: "Message cannot be empty." });
    }

    try {
        const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
            method: "POST",
            headers: {
                "Authorization": `Bearer ${process.env.OPENROUTER_API_KEY}`,
                "Content-Type": "application/json"
            },
            body: JSON.stringify({
                model: "deepseek/deepseek-chat:free",
                messages: [
                    { role: "system", content: "You are a professional medical assistant. Respond in a formal and clinical tone, ensuring accuracy and clarity in your explanations." },
                    { role: "user", content: message }
                ]
            }),
        });

        console.log("OpenRouter API response:", response); // ✅ Log full response

        const data = await response.json();
        console.log("Parsed response data:", data); // ✅ Check response structure

        const reply = data.choices?.[0]?.message?.content || "No response available.";

        res.json({ reply });

    } catch (error) {
        console.error("Error fetching chatbot response:", error);
        res.status(500).json({ error: "Failed to fetch response." });
    }
});

// File summarization endpoint
app.post("/summarize", upload.single("file"), async (req, res) => {
    if (!req.file) {
        return res.status(400).json({ error: "No file uploaded" });
    }

    try {
        const text = fs.readFileSync(req.file.path, "utf8");

        const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
            method: "POST",
            headers: {
                "Authorization": `Bearer ${process.env.OPENROUTER_API_KEY}`,
                "Content-Type": "application/json"
            },
            body: JSON.stringify({
                model: "deepseek/deepseek-chat:free",
                messages: [
                    { role: "system", content: "You are a medical AI assistant. Convert the following doctor’s notes into a structured and official medical report." },
                    { role: "user", content: `Generate a professional medical report from these notes: \n\n${text}` }
                ]
            }),
        });

        const data = await response.json();
        console.log("Summarization API Response:", JSON.stringify(data, null, 2)); // Debugging

        if (!data.choices || data.choices.length === 0) {
            return res.status(500).json({ error: "No summary generated by AI model." });
        }

        res.json({ summary: data.choices[0].message.content });

    } catch (error) {
        console.error("Error summarizing:", error);
        res.status(500).json({ error: "Failed to fetch summary." });
    } finally {
        fs.unlink(req.file.path, (err) => {
            if (err) console.error("Failed to delete file:", err);
        });
    }
});

// Start Express server
app.listen(PORT, () => {
    console.log(`Server running on port ${PORT}`);
});
